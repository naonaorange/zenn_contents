---
title: "è‡ªä½œã®MNISTå­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã£ã¦OpenCV for Unityã§æ¨è«–ã™ã‚‹"
emoji: "ğŸ˜€"
type: "tech"
topics: ["20200427","unity","tensorflow"]
published: true
---
æœ€è¿‘Unityã‚’ä½¿ã£ã¦ã„ã¾ã™ãŒã€Unityã§Deep Learningã‚’ä½¿ã£ã¦ã¿ã¾ã™ã€‚

Unityã§Deep Learningã‚’ã™ã‚‹ã¨ãã«è‰²ã€…ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒã‚ã‚Šã¾ã™ãŒã€ä»Šå›ã¯OpenCV for Unityã‚’ä½¿ã„ã¾ã™ã€‚

å®Ÿéš›ã«ã‚¢ãƒ—ãƒªã¨ã‹ã‚’ä½œã‚‹æ™‚ã‚’è€ƒæ…®ã—ã¦ã€ä¸‹ã®ã‚ˆã†ãªæ–¹é‡ã§ä½œã£ã¦ã„ãã¾ã™ã€‚
+ Deep Learningã®å­¦ç¿’éƒ¨åˆ†ã¯Unityã‚’ä½¿ã‚ãšã€Tensorflowã§è¡Œã„ã€å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ•ã‚¡ã‚¤ãƒ«å‡ºåŠ›ã™ã‚‹ã€‚
+ OpenCV for UnityãŒèª­ã¿è¾¼ã‚ã‚‹ãƒ¢ãƒ‡ãƒ«å½¢å¼ã«å¤‰æ›ã‚’è¡Œã†ã€‚
+ OpenCV for Unityã§å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ã€æ¨è«–ã ã‘è¡Œã†ã€‚
+ Windowsç’°å¢ƒã ã‘ã§ã¯ãªãAndroidç’°å¢ƒã§ã‚‚å‹•ä½œã•ã›ã‚‹(iOSã¯å°†æ¥çš„ã«å¯¾å¿œã—ã¾ã™ã€‚ã€‚ã€‚)

# æœ€çµ‚çš„ã«ã¯
äº‹å‰ã«ãƒ•ã‚¡ã‚¤ãƒ«ã«æ ¼ç´ã•ã‚Œã¦ã„ã‚‹ç”»åƒãƒ‡ãƒ¼ã‚¿ã¨æ¨è«–ã®çµæœã‚‚è¡¨ç¤ºã—ã¾ã™ã€‚
NEXT IMAGEãƒœã‚¿ãƒ³ã‚’æŠ¼ã™ã¨ã€æ¬¡ã®ç”»åƒãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦è¡¨ç¤ºã¨æ¨è«–ã‚’è¡Œã„ã¾ã™ã€‚
![](/images/20200427_opencv_unity_mnist/1.jpeg)
![](/images/20200427_opencv_unity_mnist/2.jpeg)

æœ€çµ‚çš„ãªãƒ—ãƒ­ã‚°ãƒ©ãƒ ã¯githubã«ã‚‚ã‚¢ãƒƒãƒ—ã—ã¦ã„ã¾ã™ã€‚
https://github.com/naonaorange/unity_dnn_samples/tree/master/CvDnnMnist


# å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆã™ã‚‹
ã“ã“ã¯Unityã¯é–¢ä¿‚ãªã„ã§ã™ãŒã€Tensorflowã‚’ç”¨ã„ã¦MNISTã®å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã‚’è‡ªåˆ†ã§ä½œã‚Šã¾ã™ã€‚
ã“ã“ã§ã¯åŸºæœ¬çš„ãª3å±¤ã®å…¨çµåˆå±¤ã‚’ä½œæˆã—ã¾ã—ãŸã€‚

å­¦ç¿’ã«ã¤ã„ã¦ã®ã‚³ãƒ¼ãƒ‰ãªã©ã¯ä¸‹è¨˜ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚
https://github.com/naonaorange/tensorflow_samples/blob/master/mnist.ipynb

jupyter notebookã®ã‚³ãƒ¼ãƒ‰ã‚’è‡ªåˆ†ã§å®Ÿè¡Œã—ã¦ã‚‚è‰¯ã„ã§ã™ãŒã€å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ãƒ‡ãƒ¼ã‚¿ã ã‘æ¬²ã—ã„ã¨ãã¯ä¸‹è¨˜ã®URLã‹ã‚‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚
tensorflowã®versionã¯2.xç³»ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚
https://github.com/naonaorange/tensorflow_samples/blob/master/models/mnist.h5:title

# å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®å¤‰æ›ã‚’è¡Œã†
å‰ç« ã§ä½œæˆã—ãŸå­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®å½¢å¼ã¯h5ã§ã—ãŸã€‚
ã—ã‹ã—ã€OpenCV for Unityã§ã¯ã“ã®å½¢å¼ã«å¯¾å¿œã—ã¦ã„ã¾ã›ã‚“ã€‚
ã‚ˆã£ã¦ã€pbå½¢å¼ã«å¤‰æ›ã—ã¾ã™ã€‚

h5ã‹ã‚‰pbã«å¤‰æ›ã™ã‚‹pythonãƒ„ãƒ¼ãƒ«ã‚’ä½œæˆã—ã¾ã—ãŸã®ã§ã€å®Ÿè¡Œã™ã‚‹ã ã‘ã§ä½œæˆã§ãã¾ã™ã€‚
æ³¨æ„ç‚¹ã¨ã—ã¦ã¯ã€æœ¬ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ç”¨ã™ã‚‹ã¨ãã«ã¯tensorflow 1.xç³»ã‚’ä½¿ã£ã¦ã„ã‚‹ã¨ã„ã†ã“ã¨ã§ã™ã€‚
(tensorflow 2.xã§ã®å‹•ä½œç¢ºèªãŒãªã„ã ã‘ã§ã€å‹•ãã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚)
https://github.com/naonaorange/dnn_model_converter

# Mnist datasetã®ç”»åƒãƒ‡ãƒ¼ã‚¿ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«å‡ºåŠ›ã™ã‚‹
pythonã§tensorflowã‚’ä½¿ç”¨ã—ã¦ã„ã‚‹åˆ†ã«ã¯ãƒãƒƒãƒˆã‹ã‚‰Mnist datasetã‹ã‚‰å…¥åŠ›ã™ã‚‹ç”»åƒãƒ‡ãƒ¼ã‚¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã§ãã¾ã™ã€‚

ã—ã‹ã—ã€Unityç’°å¢ƒä¸‹ã§Mnist datasetã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã®ã¯å¤§å¤‰ãªã®ã§ã€
pythonã§å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã‚’csvãƒ•ã‚¡ã‚¤ãƒ«ã«å‡ºåŠ›ã—ã€Unityã§ã¯ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ç”»åƒãƒ‡ãƒ¼ã‚¿ã‚’ä½œã‚Šã¾ã™ã€‚

csvãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã¨ã—ã¦ã¯ã€1è¡Œã§1ç”»åƒåˆ†ã§ã™ã€‚
28*28ã®ç”»åƒã§ã™ã®ã§ã€748åˆ—ã‚ã‚Šã¾ã™ã€‚

https://github.com/naonaorange/tensorflow_samples/blob/master/export_mnist_dataset_to_csv.ipynb

ã“ã¡ã‚‰ã‚‚ã€å‡ºåŠ›ã•ã‚ŒãŸcsvãƒ•ã‚¡ã‚¤ãƒ«ã ã‘ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ãŸã„æ–¹ã¯ã“ã¡ã‚‰ã‹ã‚‰
https://github.com/naonaorange/tensorflow_samples/blob/master/data/mnist_dataset.csv:title


# Unityãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ã®åˆæœŸè¨­å®š

## OpenCV for Unityã®importã™ã‚‹
æ–°è¦ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½œæˆã—ãŸã‚‰ã€Asset Storeã‹ã‚‰OpenCV for Unityã‚’importã—ã¦ãã ã•ã„ã€‚

## UIã®ä½œæˆ
RawImage, Text, Butttonã‚’è¿½åŠ ã—ã¾ã™ã€‚
![](/images/20200427_opencv_unity_mnist/3.jpeg)

## å¿…è¦ãªãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¿½åŠ ã™ã‚‹
mnist.pbãƒ•ã‚¡ã‚¤ãƒ«ã¯Assets/StreamingAssetså†…ã«ã€mnist_dataset.csvãƒ•ã‚¡ã‚¤ãƒ«ã¯Asset/Resourceså†…ã«è¿½åŠ ã—ã¾ã™ã€‚
![](/images/20200427_opencv_unity_mnist/4.jpeg)

# C# Scriptã‚’ä½œæˆã™ã‚‹
RawImageController.csã‚’ä½œæˆã—ã€UIã®RawImageã«ã‚¢ã‚¿ãƒƒãƒã—ã¾ã™ã€‚

```cs
using System.Collections;
using System.Collections.Generic;
using UnityEngine;
using UnityEngine.UI;
using System.IO;

using OpenCVForUnity.CoreModule;
using OpenCVForUnity.UnityUtils;
using OpenCVForUnity.DnnModule;

public class RawImageController : MonoBehaviour
{
    private Texture2D texture;
    GameObject answerText;

    private List<List<byte>> mnist_dataset;
    private int mnist_dataset_idx;

    private Net net;
    private const int IMG_WIDTH = 28;
    private const int IMG_HEIGHT = 28;
    private const string MODEL_FILE_PATH = "mnist.pb";

    // Start is called before the first frame update
    void Start()
    {
        answerText = GameObject.Find("Text");
        mnist_dataset_idx = 0;
        mnist_dataset = read_mnist_dataset();

        string model_filepath = Utils.getFilePath(MODEL_FILE_PATH);
        net = Dnn.readNetFromTensorflow(model_filepath);
        if (net.empty()) Debug.LogError("model file is not loaded.");

        show_image();
        predict();
    }

    // Update is called once per frame
    void Update()
    {
    }

    public void go_to_next_image()
    {
        mnist_dataset_idx += 1;
        if (mnist_dataset.Count <= mnist_dataset_idx) mnist_dataset_idx = 0;

        show_image();
        predict();
    }

    void show_image()
    {
        List<byte> mnist_data = mnist_dataset[mnist_dataset_idx];
        Mat disp_img = new Mat(IMG_HEIGHT, IMG_WIDTH, CvType.CV_8UC3);
        for(int y = 0; y < IMG_HEIGHT; y++)
        {
            for(int x = 0; x < IMG_WIDTH; x++)
            {
                byte p = mnist_data[y * IMG_HEIGHT + x];
                disp_img.put(y, x, new byte[3] { p, p, p });
            }
        }
        texture = new Texture2D(IMG_WIDTH, IMG_HEIGHT);
        Utils.matToTexture2D(disp_img, texture);
        GetComponent<RawImage>().texture = texture;

        /*
        //Matã‚’ä½¿ç”¨ã›ãštextureã«ç”»ç´ ã‚’æ ¼ç´ã™ã‚‹
        texture = new Texture2D(IMG_WIDTH, IMG_HEIGHT);
        List<float> data = mnist_data[1];
        List<List<float>> d = convert_data(data, true);
        Debug.Log(d.Count + " , " + d[0].Count);

        for(int y = 0; y < IMG_HEIGHT; y++)
        {
            for(int x = 0; x < IMG_WIDTH; x++)
            {
                texture.SetPixel(x, y, new Color(d[y][x], d[y][x], d[y][x]));
            }
        }
        texture.Apply(false);
        GetComponent<RawImage>().texture = texture;
        */
    }

    void predict()
    {
        List<byte> mnist_data = mnist_dataset[mnist_dataset_idx];

        Mat input_img = new Mat(1, IMG_HEIGHT * IMG_WIDTH, CvType.CV_32FC1);
        for(int i = 0; i < mnist_data.Count; i++)
        {
            float p = (float)mnist_data[i] / 255.0f;
            input_img.put(0, i, p);
        }

        Mat blob = Dnn.blobFromImage(input_img);
        net.setInput(blob);
        Mat prob = net.forward();

        (int max_idx, float max_value) = get_max_idx(prob);
        answerText.GetComponent<Text>().text = "idx : " + max_idx + " , value : " + max_value.ToString("F2");
    }

    List<List<byte>> read_mnist_dataset()
    {
        TextAsset csv = Resources.Load("mnist_dataset") as TextAsset;
        StringReader reader = new StringReader(csv.text);
        List<List<byte>> data = new List<List<byte>>();

        while(reader.Peek() != -1)
        {
            string[] str_line = reader.ReadLine().Split(',');
            List<byte> line = new List<byte>();
            foreach(string str in str_line)
            {
                line.Add(byte.Parse(str));
            }
            data.Add(line);
        }
        return data;
    }

    List<List<float>> convert_data( List<float> data_array,
                                    bool is_texture_axis=false)
    {
        List<List<float>> d = new List<List<float>>();
        for (int i = 0; i < IMG_HEIGHT; i++) d.Add(new List<float>());
        
        for(int y = 0; y < IMG_HEIGHT; y++)
        {
            for(int x = 0; x < IMG_WIDTH; x++)
            {
                if (is_texture_axis)
                {
                    d[IMG_HEIGHT - y -1].Add(data_array[y * IMG_HEIGHT + x]);
                }
                else
                {
                    d[y].Add(data_array[y * IMG_HEIGHT + x]);
                }
            }
        }
        return d;
    }

    (int idx, float value) get_max_idx(Mat prob)
    {
        int max_idx = 0;
        float max_value = 0.0f;

        for(int i = 0; i < prob.width(); i++)
        {
            float tmp = (float)prob.get(0, i)[0];
            if(max_value < tmp)
            {
                max_value = tmp;
                max_idx = i;
            }
        }
        return (max_idx, max_value);
    }
}
```

ã“ã“ã§ã®ãƒã‚¤ãƒ³ãƒˆã¨ã—ã¦ã¯ã€

### è¡¨ç¤ºç”¨ã®ç”»åƒãƒ‡ãƒ¼ã‚¿ä½œæˆã«ã¤ã„ã¦
RawImageã¸ã®è¡¨ç¤ºãƒ‡ãƒ¼ã‚¿ã‚’mnist datasetã‹ã‚‰ä½œæˆã—ã¦ã„ã¾ã™ã€‚
æ‰‹é †ã¨ã—ã¦ã¯ã€mnist datasetã®ãƒ‡ãƒ¼ã‚¿ã‚’Matã«æ ¼ç´ã—ã€texuture2dã«å¤‰æ›ã—ã¦è¡¨ç¤ºã—ã¾ã™ã€‚
ä»Šå›ã®ã‚µãƒ³ãƒ—ãƒ«ã§ã¯ã‚ã–ã‚ã–Matã‚’çµŒç”±ã™ã‚‹å¿…è¦ã¯ãªã„ã§ã™ãŒã€è¿½åŠ ã®ç”»åƒå‡¦ç†ãŒå¿…è¦ã§ã‚ã‚Œã°ã€Matå½¢å¼ã§è¡Œã†ã¨ç°¡å˜ã§ã™ã€‚

ã¡ãªã¿ã«Matå½¢å¼ã‚’ä»‹ã•ãªã„ã§ã€texture2dã«ç›´æ¥æ ¼ç´ã™ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ã€‚ãã®éš›ã«ã¯ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆã—ã¦ã„ã‚‹ã‚³ãƒ¼ãƒ‰ã‚’ä½¿ã£ã¦ãã ã•ã„ã€‚
ã“ã®éš›ã«ã¯Matã¨texture2dã§ã¯ç”»ç´ ã®é…åˆ—é †ç•ªãŒç•°ãªã‚Šã¾ã™ã®ã§ã€æ³¨æ„ã—ã¦ãã ã•ã„ã€‚
é…åˆ—é †ç•ªã«ã¤ã„ã¦ã¯ä¸‹è¨˜ã®è¨˜äº‹ãŒè©³ã—ã„ã§ã™ã€‚
https://qiita.com/utibenkei/items/d1050253fc586f17f0ec

```cs
        Mat disp_img = new Mat(IMG_HEIGHT, IMG_WIDTH, CvType.CV_8UC3);
        for(int y = 0; y < IMG_HEIGHT; y++)
        {
            for(int x = 0; x < IMG_WIDTH; x++)
            {
                byte p = mnist_data[y * IMG_HEIGHT + x];
                disp_img.put(y, x, new byte[3] { p, p, p });
            }
        }
        texture = new Texture2D(IMG_WIDTH, IMG_HEIGHT);
        Utils.matToTexture2D(disp_img, texture);
```

### æ¨è«–ã®å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã«ã¤ã„ã¦
å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆã™ã‚‹éš›ã«ã¯ã€å­¦ç¿’æ™‚ã®å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã¨åˆã‚ã›ã‚‹ã“ã¨ãŒå¿…è¦ã ã¨æ€ã„ã¾ã™ã€‚
å­¦ç¿’ã®æ™‚ã«ã¯ã€å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ãŒ728(ç”»åƒãƒ‡ãƒ¼ã‚¿28*28ã‚’1æ¬¡å…ƒé…åˆ—ã«ã—ãŸã‚‚ã®)ã§ã€0ã‹ã‚‰1ã«æ­£è¦åŒ–ã—ã¾ã—ãŸã€‚
ãã‚Œã«åˆã‚ã›ã¦ã€CV_32F1ã‚’ä½¿ã„ã€255ã§å‰²ã£ã¦æ­£è¦åŒ–ã—ãŸå…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆã—ã¦ã„ã¾ã™ã€‚
```cs
        Mat input_img = new Mat(1, IMG_HEIGHT * IMG_WIDTH, CvType.CV_32FC1);
        for(int i = 0; i < mnist_data.Count; i++)
        {
            float p = (float)mnist_data[i] / 255.0f;
            input_img.put(0, i, p);
        }
```

## Buttonã®onClickã‚¤ãƒ™ãƒ³ãƒˆã‚’ç™»éŒ²ã™ã‚‹
Buttonã®onClickã‚¤ãƒ™ãƒ³ãƒˆã«go_to_next_imageé–¢æ•°ã‚’ç™»éŒ²ã—ã¾ã™ã€‚

# å‚è€ƒ
https://www.slideshare.net/takmin/run-keras-model-on-opencv

https://qiita.com/yanosen_jp/items/4a35f31831b7f7b5d0cd

https://qiita.com/yoda/items/05b58a8f439f478a6210






